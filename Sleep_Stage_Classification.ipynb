{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "from sklearn.tree import DecisionTreeClassifier as dtc\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import scipy\n",
    "import scipy.io as sio\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tqdm import tqdm_notebook \n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Labels\n",
    "hyp01 = scipy.io.loadmat('SC4001E0-PSG_hyp')\n",
    "hyp11 = scipy.io.loadmat('SC4011E0-PSG_hyp')\n",
    "hyp12 = scipy.io.loadmat('SC4012E0-PSG_hyp')\n",
    "hyp21 = scipy.io.loadmat('SC4021E0-PSG_hyp')\n",
    "hyp22 = scipy.io.loadmat('SC4022E0-PSG_hyp')\n",
    "hyp31 = scipy.io.loadmat('SC4031E0-PSG_hyp')\n",
    "hyp32 = scipy.io.loadmat('SC4032E0-PSG_hyp')\n",
    "hyp41 = scipy.io.loadmat('SC4041E0-PSG_hyp')\n",
    "hyp42 = scipy.io.loadmat('SC4042E0-PSG_hyp')\n",
    "hyp51 = scipy.io.loadmat('SC4051E0-PSG_hyp')\n",
    "\n",
    "hyp01 = hyp01['hypnogram'][799:1633]\n",
    "hyp11 = hyp11['hypnogram'][799:1633]\n",
    "hyp12 = hyp12['hypnogram'][799:1633]\n",
    "hyp21 = hyp21['hypnogram'][799:1633]\n",
    "hyp22 = hyp22['hypnogram'][799:1633]\n",
    "hyp31 = hyp31['hypnogram'][799:1633]\n",
    "hyp32 = hyp32['hypnogram'][799:1633]\n",
    "hyp41 = hyp41['hypnogram'][799:1633]\n",
    "hyp42 = hyp42['hypnogram'][799:1633]\n",
    "hyp51 = hyp51['hypnogram'][799:1633]\n",
    "\n",
    "hypt = np.concatenate((hyp01, hyp11, hyp12, hyp21, hyp22, hyp31, hyp32, hyp41, hyp42, hyp51), axis = 0)\n",
    "\n",
    "###Load in features\n",
    "data1 = scipy.io.loadmat('features(10)_cwt.mat')['features']\n",
    "\n",
    "data01 = data1[(799):(1633),:]\n",
    "data02 = data1[(799+((1)*1633)):(1633+((1)*1633)),:]\n",
    "data03 = data1[(799+(2)*1633):(1633+(2)*1633),:]\n",
    "data04 = data1[(799+(3)*1633):(1633+(3)*1633),:]\n",
    "data05 = data1[(799+(4)*1633):(1633+(4)*1633),:]\n",
    "data06 = data1[(799+(5)*1633):(1633+(5)*1633),:]\n",
    "data07 = data1[(799+(6)*1633):(1633+(6)*1633),:]\n",
    "data08 = data1[(799+(7)*1633):(1633+(7)*1633),:]\n",
    "data09 = data1[(799+(8)*1633):(1633+(8)*1633),:]\n",
    "data10 = data1[(799+(9)*1633):(1633+(9)*1633),:]\n",
    "\n",
    "data = np.concatenate((data01, data02, data03, data04, data05, data06, data07, data08, data09, data10), axis = 0)\n",
    "m, n = hypt.shape\n",
    "\n",
    "for i in range(m):\n",
    "    if hypt[i,1]==4:\n",
    "        hypt[i,1]=3\n",
    "    elif hypt[i,1]==6:\n",
    "        hypt[i,1]=0\n",
    "\n",
    "data = (data-np.mean(data,axis=0))/np.std(data,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Random_Forest():\n",
    "\n",
    "    def __init__(self , data , labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.data_labels = np.concatenate((data,labels.reshape([-1,1])), axis = 1)\n",
    "        self.all_trees = []\n",
    "        self.track_features = []\n",
    "\n",
    "        \n",
    "\n",
    "    def bootstrap(self):\n",
    "        number_of_samples = self.data_labels.shape[(0)]\n",
    "        bootstrapped_idx = np.random.randint(number_of_samples-1, size = (number_of_samples))\n",
    "        bootstrapped_data = []\n",
    "        for i in (bootstrapped_idx):\n",
    "\n",
    "            bootstrapped_data.append(self.data_labels[i])\n",
    "    \n",
    "        return bootstrapped_data\n",
    "    \n",
    "    def random_forest_classification(self, num_of_trees): # labels = hypt , data = data\n",
    "        total_num_of_features = self.data.shape[(1)]\n",
    "   \n",
    "        features = int(np.floor(np.sqrt(total_num_of_features)))\n",
    "        \n",
    "        \n",
    "        for i in range(num_of_trees):\n",
    "            bootstrapped_data = self.bootstrap()\n",
    "            random_indices = np.random.randint(0,total_num_of_features,size = (features))\n",
    "            self.track_features.append(random_indices.tolist())\n",
    "            bootstrapped_data = np.array(bootstrapped_data)\n",
    "            bootstrapped_data_data = bootstrapped_data[:,:-1]\n",
    "            random_feature_selection = bootstrapped_data_data[: , random_indices] \n",
    "\n",
    "            single_tree = dtc()\n",
    "            single_tree.fit(random_feature_selection,bootstrapped_data[:,-1])\n",
    "            self.all_trees.append(single_tree)\n",
    "\n",
    "            #Data_for_tree = np.concatenate((self.data,self.labels.reshape([-1,1])), axis = 1)\n",
    "        #print(self.track_features)    \n",
    "        return self.all_trees\n",
    "\n",
    "    def random_forest_predict(self, test_data):\n",
    "        predictions = []\n",
    "        results = []\n",
    "        for i,j in zip(self.all_trees,self.track_features):\n",
    "            predictions.append((i.predict(test_data[:,j])).tolist())\n",
    "        #print(predictions[1])\n",
    "\n",
    "        predictions = np.array(predictions)\n",
    "        predictions = predictions.astype(\"int64\")\n",
    "        for i in range(np.shape(predictions)[1]):\n",
    "            results.append(np.argmax(np.bincount(predictions[:,i])))\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  74.70023980815348 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>354</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0   1    2   3   5\n",
       "Actual                         \n",
       "0          147   1    4   0   1\n",
       "1           14  12   38   0   7\n",
       "2            2   5  354   8  15\n",
       "3            0   0   47  68   0\n",
       "5            4   5   60   0  42"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train , x_test , y_train , y_test = train_test_split(data,hypt[:,1], test_size=0.1)\n",
    "rf = Random_Forest(x_train,y_train)\n",
    "data1 = (rf.random_forest_classification(40))\n",
    "pred = rf.random_forest_predict(x_test)\n",
    "print(\"Accuracy is \",(y_test == pred).sum()/len(y_test)*100,\"%\")\n",
    "aa = pd.crosstab(np.array(y_test), np.array(pred), rownames = ['Actual'], colnames = ['Predicted'])\n",
    "aa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class K_Nearest_Neighbors:\n",
    "\n",
    "    def __init__(self, K):\n",
    "        self.K = K\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "    \n",
    "    def knn_predict(self, X_test):\n",
    "        Result = [] \n",
    "        for i in range(len(X_test)):\n",
    "            distances = [] \n",
    "            classifiers = [] \n",
    "            for j in range(len(self.X_train)):\n",
    "                dist = scipy.spatial.distance.euclidean(self.X_train[j] ,X_test[i]) \n",
    "                distances.append([dist, j])\n",
    "            distances.sort() \n",
    "            distances = distances[0:self.K] \n",
    "            for distances, j in distances:\n",
    "                classifiers.append(y_train[j])\n",
    "                \n",
    "            temp = Counter(classifiers).most_common(1)[0][0] \n",
    "            Result.append(temp)\n",
    "            \n",
    "        return Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  81.65467625899281 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>354</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0   1    2   3   5\n",
       "Actual                         \n",
       "0          147   1    4   0   1\n",
       "1           14  12   38   0   7\n",
       "2            2   5  354   8  15\n",
       "3            0   0   47  68   0\n",
       "5            4   5   60   0  42"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN = K_Nearest_Neighbors(17)\n",
    "KNN.fit(x_train,y_train)\n",
    "y_pred = KNN.knn_predict(x_test)\n",
    "print(\"Accuracy is \",(y_test == y_pred).sum()/len(y_test)*100,\"%\")\n",
    "aa = pd.crosstab(np.array(y_test), np.array(pred), rownames = ['Actual'], colnames = ['Predicted'])\n",
    "aa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm(x,y,lr,lambd,epochs = 100): #lambd = 1/nC\n",
    "    n = x.shape[0]\n",
    "   \n",
    "    w = np.zeros([len(x[0]),1])\n",
    "    loss_ar = []\n",
    "    b = 0\n",
    "    acc_ar = []\n",
    "    acc_ar.append(0)\n",
    "    for epoch in range(epochs):\n",
    "        dw = np.zeros(w.shape)\n",
    "      \n",
    "        z = np.maximum(0,1-y*(np.dot(x,w)+b))\n",
    "        loss = np.sum(z) + lambd*np.sum(w*w)/2\n",
    "        loss_ar.append(loss)\n",
    "        dw = lambd*w - 1/n *(np.sum((x*y),axis = 0).reshape(-1,1))\n",
    "        q = x*y\n",
    "        for i in range(n):\n",
    "            if(z[i] == 0):\n",
    "                q[i][:] = 0\n",
    "        dw = lambd*w - (np.sum(q,axis = 0).reshape(-1,1))/n\n",
    "        w = w - lr * dw\n",
    "        acc = predict(w,b,x,y)\n",
    "        acc_ar.append(acc)\n",
    "        b = lr*np.sum(y - np.dot(x,w))/n\n",
    "        if(loss<1):\n",
    "            print(\"epoch {}, loss = {}, accuaracy = {}.\\nTerminating due to reaching threshold of loss < 1\".format(epoch+1,loss,acc))\n",
    "            return w,b,loss_ar,acc_ar\n",
    "        if(acc>99):\n",
    "            print(\"epoch {}, loss = {}, accuaracy = {}.\\nTerminating due to reaching threshold of train accuracy > 99\".format(epoch+1,loss,acc))\n",
    "            return w,b,loss_ar,acc_ar\n",
    "        if(not epoch):\n",
    "            print(\"epoch {}, loss = {}, accuaracy = {}.\".format(epoch,loss,acc))\n",
    "        elif(epoch <101):\n",
    "            if(epoch%99 == 0):\n",
    "                print(\"epoch {}, loss = {}, accuaracy = {}.\".format(epoch+1,loss,acc))\n",
    "        elif(epoch%499 ==0):\n",
    "            print(\"epoch {}, loss = {}, accuaracy = {}.\".format(epoch+1,loss,acc))\n",
    "        \n",
    "    return w,b,loss_ar,acc_ar\n",
    "\n",
    "def predict(w,b,x,y):\n",
    "    pred = np.dot(x,w)+b\n",
    "    n = x.shape[0]\n",
    "    pred[pred>0] = 1\n",
    "    pred[pred<0] = -1\n",
    "    t = np.sum(pred == y)\n",
    "    #print(x.shape,y.shape)\n",
    "    acc = t/n\n",
    "    return acc*100\n",
    "\n",
    "def train_multi_svm(train_set,test_set,y_train,y_test):\n",
    "    accuracy = []\n",
    "    arr = len(np.unique(y_test))\n",
    "    loss_t = []\n",
    "    parameters = {}\n",
    "    print(\"Found {} unique labels. Training {} Support vector machines\".format(arr,arr))\n",
    "    for i in range(len(np.unique(y_test))):         \n",
    "        y = y_train.copy()\n",
    "        \n",
    "        y[y != i] = -1\n",
    "        y[y == i] = 1\n",
    "        y = y.reshape(-1,1)\n",
    "        print(y.shape)\n",
    "        #print(\"test\",np.unique(y))\n",
    "        yt = y_test.copy()    \n",
    "        yt[yt != i] = -1\n",
    "        yt[yt == i] = 1\n",
    "        #print(\"test\",np.unique(yt))\n",
    "        yt = yt.reshape(-1,1)\n",
    "        print(\"training SVM {} of 5\".format(i+1))\n",
    "        w,b,loss,acc = train_svm(train_set,y,0.01,0.1,1000)  \n",
    "        print(\"Test set accuracy = {}\".format(predict(w,b,test_set,yt)))\n",
    "        parameters[i] = {}\n",
    "        parameters[i][\"accuracy\"] = acc\n",
    "        parameters[i][\"test_accuracy\"] = predict(w,b,test_set,yt)\n",
    "        parameters[i][\"loss\"] = loss\n",
    "        parameters[i][\"w\"] = w\n",
    "        parameters[i][\"b\"] = b\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 unique labels. Training 5 Support vector machines\n",
      "(7506, 1)\n",
      "training SVM 1 of 5\n",
      "epoch 0, loss = 7506.0, accuaracy = 75.59285904609646.\n",
      "epoch 100, loss = 4713.70265833951, accuaracy = 76.60538236077804.\n",
      "epoch 500, loss = 3937.2353793901243, accuaracy = 80.10924593658406.\n",
      "epoch 999, loss = 3662.908099940728, accuaracy = 81.65467625899281.\n",
      "Test set accuracy = 80.69544364508393\n",
      "(7506, 1)\n",
      "training SVM 2 of 5\n",
      "epoch 0, loss = 7506.0, accuaracy = 59.379163335997866.\n",
      "epoch 100, loss = 6957.31510031816, accuaracy = 59.96536104449773.\n",
      "epoch 500, loss = 6832.323303590533, accuaracy = 59.79216626698641.\n",
      "epoch 999, loss = 6824.510689916732, accuaracy = 59.63229416466827.\n",
      "Test set accuracy = 59.47242206235012\n",
      "(7506, 1)\n",
      "training SVM 3 of 5\n",
      "epoch 0, loss = 7506.0, accuaracy = 72.95496935784705.\n",
      "epoch 100, loss = 5963.605544246362, accuaracy = 73.40794031441513.\n",
      "epoch 500, loss = 5238.873648717531, accuaracy = 72.44870770050626.\n",
      "epoch 999, loss = 5049.511008912695, accuaracy = 73.26139088729016.\n",
      "Test set accuracy = 73.86091127098321\n",
      "(7506, 1)\n",
      "training SVM 4 of 5\n",
      "epoch 0, loss = 7506.0, accuaracy = 55.94191313615774.\n",
      "epoch 100, loss = 6327.146087089629, accuaracy = 56.19504396482814.\n",
      "epoch 500, loss = 6075.490404610516, accuaracy = 56.92779110045297.\n",
      "epoch 999, loss = 6053.753325425741, accuaracy = 57.394084732214225.\n",
      "Test set accuracy = 57.434052757793765\n",
      "(7506, 1)\n",
      "training SVM 5 of 5\n",
      "epoch 0, loss = 7506.0, accuaracy = 43.871569411137756.\n",
      "epoch 2, loss = 7430.936386047769, accuaracy = 100.0.\n",
      "Terminating due to reaching threshold of train accuracy > 99\n",
      "Test set accuracy = 100.0\n"
     ]
    }
   ],
   "source": [
    "parametres = train_multi_svm(x_train,x_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFSN_MultiClass:\n",
    "  \n",
    "  def __init__(self, n_inputs, n_outputs, hidden_sizes=[3]):\n",
    "    self.nx = n_inputs\n",
    "    self.ny = n_outputs\n",
    "    self.nh = len(hidden_sizes)\n",
    "    self.sizes = [self.nx] + hidden_sizes + [self.ny] \n",
    "\n",
    "    self.W = {}\n",
    "    self.B = {}\n",
    "    for i in range(self.nh+1):\n",
    "      self.W[i+1] = np.random.randn(self.sizes[i], self.sizes[i+1])\n",
    "      self.B[i+1] = np.zeros((1, self.sizes[i+1]))\n",
    "      \n",
    "  def sigmoid(self, x):\n",
    "    return 1.0/(1.0 + np.exp(-x))\n",
    "  \n",
    "  def softmax(self, x):\n",
    "    exps = np.exp(x)\n",
    "    return exps / np.sum(exps)\n",
    "\n",
    "  def forward_pass(self, x):\n",
    "    self.A = {}\n",
    "    self.H = {}\n",
    "    self.H[0] = x.reshape(1, -1)\n",
    "    for i in range(self.nh):\n",
    "      self.A[i+1] = np.matmul(self.H[i], self.W[i+1]) + self.B[i+1]\n",
    "      self.H[i+1] = self.sigmoid(self.A[i+1])\n",
    "    self.A[self.nh+1] = np.matmul(self.H[self.nh], self.W[self.nh+1]) + self.B[self.nh+1]\n",
    "    self.H[self.nh+1] = self.softmax(self.A[self.nh+1])\n",
    "    return self.H[self.nh+1]\n",
    "  \n",
    "  def predict(self, X):\n",
    "    Y_pred = []\n",
    "    for x in X:\n",
    "      y_pred = self.forward_pass(x)\n",
    "      Y_pred.append(y_pred)\n",
    "    return np.array(Y_pred).squeeze()\n",
    " \n",
    "  def grad_sigmoid(self, x):\n",
    "    return x*(1-x) \n",
    "  \n",
    "  def cross_entropy(self,label,pred):\n",
    "    yl=np.multiply(pred,label)\n",
    "    yl=yl[yl!=0]\n",
    "    yl=-np.log(yl)\n",
    "    yl=np.mean(yl)\n",
    "    return yl\n",
    " \n",
    "  def grad(self, x, y):\n",
    "    self.forward_pass(x)\n",
    "    self.dW = {}\n",
    "    self.dB = {}\n",
    "    self.dH = {}\n",
    "    self.dA = {}\n",
    "    L = self.nh + 1\n",
    "    self.dA[L] = (self.H[L] - y)\n",
    "    for k in range(L, 0, -1):\n",
    "      self.dW[k] = np.matmul(self.H[k-1].T, self.dA[k])\n",
    "      self.dB[k] = self.dA[k]\n",
    "      self.dH[k-1] = np.matmul(self.dA[k], self.W[k].T)\n",
    "      self.dA[k-1] = np.multiply(self.dH[k-1], self.grad_sigmoid(self.H[k-1])) \n",
    "    \n",
    "  def fit(self, X, Y, epochs=100, initialize='True', learning_rate=0.01, display_loss=False):\n",
    "      \n",
    "    if display_loss:\n",
    "      loss = {}\n",
    "      \n",
    "    if initialize:\n",
    "      for i in range(self.nh+1):\n",
    "        self.W[i+1] = np.random.randn(self.sizes[i], self.sizes[i+1])\n",
    "        self.B[i+1] = np.zeros((1, self.sizes[i+1]))\n",
    "        \n",
    "    for epoch in tqdm_notebook(range(epochs), total=epochs, unit=\"epoch\"):\n",
    "      dW = {}\n",
    "      dB = {}\n",
    "      for i in range(self.nh+1):\n",
    "        dW[i+1] = np.zeros((self.sizes[i], self.sizes[i+1]))\n",
    "        dB[i+1] = np.zeros((1, self.sizes[i+1]))\n",
    "      for x, y in zip(X, Y):\n",
    "        self.grad(x, y)\n",
    "        for i in range(self.nh+1):\n",
    "          dW[i+1] += self.dW[i+1]\n",
    "          dB[i+1] += self.dB[i+1]\n",
    "                  \n",
    "      m = X.shape[1]\n",
    "      for i in range(self.nh+1):\n",
    "        self.W[i+1] -= learning_rate * (dW[i+1]/m)\n",
    "        self.B[i+1] -= learning_rate * (dB[i+1]/m)\n",
    "        \n",
    "      if display_loss:\n",
    "        Y_pred = self.predict(X) \n",
    "        loss[epoch] = self.cross_entropy(Y, Y_pred)\n",
    "    \n",
    "    if display_loss:\n",
    "      plt.plot(loss.values())\n",
    "      plt.xlabel('Epochs')\n",
    "      plt.ylabel('CE')\n",
    "      plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-c9483c962252>:74: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for epoch in tqdm_notebook(range(epochs), total=epochs, unit=\"epoch\"):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92cc7afa4f3d4ff3a38227e552ba0729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy 0.67\n"
     ]
    }
   ],
   "source": [
    "enc = OneHotEncoder()\n",
    "y_OH_train = enc.fit_transform(np.expand_dims(y_train,1)).toarray()\n",
    "y_OH_test = enc.fit_transform(np.expand_dims(y_test,1)).toarray()\n",
    "ffsn_multi = FFSN_MultiClass(7,5,[4,4])\n",
    "ffsn_multi.fit(x_train,y_OH_train,epochs=1500,learning_rate=.006,display_loss=True)\n",
    "\n",
    "\n",
    "Y_pred_train = ffsn_multi.predict(x_train)\n",
    "Y_pred_train = np.argmax(Y_pred_train,1)\n",
    "\n",
    "Y_pred_val = ffsn_multi.predict(x_test)\n",
    "Y_pred_val = np.argmax(Y_pred_val,1)\n",
    "\n",
    "accuracy_train = accuracy_score(Y_pred_train, y_train)\n",
    "accuracy_val = accuracy_score(Y_pred_val, y_test)\n",
    "\n",
    "print(\"Validation accuracy\", round(accuracy_val, 2))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e48751a2e34d595a2cec059cf3591fb26f52f348ef6ba549e15b56ca6a208700"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
